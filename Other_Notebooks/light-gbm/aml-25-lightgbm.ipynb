{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T10:46:12.002673Z",
     "iopub.status.busy": "2025-10-12T10:46:12.001797Z",
     "iopub.status.idle": "2025-10-12T10:46:16.599540Z",
     "shell.execute_reply": "2025-10-12T10:46:16.598664Z",
     "shell.execute_reply.started": "2025-10-12T10:46:12.002642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install sentence-transformers lightgbm --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T10:47:00.416652Z",
     "iopub.status.busy": "2025-10-12T10:47:00.415793Z",
     "iopub.status.idle": "2025-10-12T10:47:19.781201Z",
     "shell.execute_reply": "2025-10-12T10:47:19.780386Z",
     "shell.execute_reply.started": "2025-10-12T10:47:00.416621Z"
    },
    "id": "BQM675XKwdJr",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-12 10:47:13.743640: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760266033.900217     310 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760266033.950121     310 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Path Configuration for Kaggle ---\n",
    "\n",
    "# Add the directory containing your helper scripts to the Python path\n",
    "sys.path.append('/kaggle/input/helpers')\n",
    "\n",
    "# Now you can import your custom classes\n",
    "from cat_transform import CatalogDataTransformer\n",
    "from catalog_feature import CatalogFeatureExtractor\n",
    "from img_transform import process_images_in_parallel, transform_pipeline\n",
    "from img_feature import CLIPImageFeatureExtractor\n",
    "\n",
    "# Input data paths\n",
    "TRAIN_CSV_PATH = \"/kaggle/input/amazon-ml-data/student_resource/dataset/train.csv\"\n",
    "TEST_CSV_PATH = \"/kaggle/input/amazon-ml-data/student_resource/dataset/test.csv\"\n",
    "\n",
    "# Writable directory for outputs\n",
    "KAGGLE_WORKING_DIR = \"/kaggle/working\"\n",
    "ALL_IMAGES_DIR = os.path.join(KAGGLE_WORKING_DIR,'all_processed_images')\n",
    "TRANSFORMED_DATA_DIR = os.path.join(KAGGLE_WORKING_DIR, 'transformed_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-12T10:47:45.308077Z",
     "iopub.status.busy": "2025-10-12T10:47:45.306776Z",
     "iopub.status.idle": "2025-10-12T10:47:48.774779Z",
     "shell.execute_reply": "2025-10-12T10:47:48.773987Z",
     "shell.execute_reply.started": "2025-10-12T10:47:45.308046Z"
    },
    "id": "LYU3CcGrwf5c",
    "outputId": "936fad46-50f9-45a9-d0e5-ae4c4567997a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Loading and combining train and test data...\n",
      "Combined DataFrame shape: (150000, 3)\n"
     ]
    }
   ],
   "source": [
    "# -- 1. Load and Combine Datasets --\n",
    "print(\"Step 1: Loading and combining train and test data...\")\n",
    "train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "test_df = pd.read_csv(TEST_CSV_PATH)\n",
    "\n",
    "# Store sample IDs for later splitting\n",
    "train_ids = train_df['sample_id']\n",
    "test_ids = test_df['sample_id']\n",
    "# Store the target variable separately\n",
    "y_train_raw = train_df['price']\n",
    "\n",
    "# Combine for unified processing\n",
    "all_df = pd.concat([\n",
    "    train_df.drop(columns=['price']),\n",
    "    test_df\n",
    "], ignore_index=True)\n",
    "\n",
    "print(f\"Combined DataFrame shape: {all_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-12T10:49:01.330526Z",
     "iopub.status.busy": "2025-10-12T10:49:01.329668Z",
     "iopub.status.idle": "2025-10-12T10:52:48.935612Z",
     "shell.execute_reply": "2025-10-12T10:52:48.934615Z",
     "shell.execute_reply.started": "2025-10-12T10:49:01.330498Z"
    },
    "id": "eoxKw0gpwml8",
    "outputId": "918f6609-1e36-4138-8198-5a2cf35b3561",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 149998 existing images out of 150000 total rows\n"
     ]
    }
   ],
   "source": [
    "# -- 2. Process All Images Simultaneously --\n",
    "print(\"\\nStep 2: Downloading and transforming all images...\")\n",
    "process_images_in_parallel(\n",
    "    image_links=all_df['image_link'].dropna().tolist(),\n",
    "    download_folder=ALL_IMAGES_DIR,\n",
    "    transform=transform_pipeline\n",
    ")\n",
    "all_df['image_path'] = all_df['image_link'].apply(\n",
    "    lambda url: os.path.join(ALL_IMAGES_DIR, os.path.basename(url)) if isinstance(url, str) else None\n",
    ")\n",
    "\n",
    "# Verify if images actually exist\n",
    "existing_images = all_df['image_path'].apply(lambda x: os.path.exists(x) if x else False)\n",
    "print(f\"Found {existing_images.sum()} existing images out of {len(all_df)} total rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T10:54:08.021935Z",
     "iopub.status.busy": "2025-10-12T10:54:08.020996Z",
     "iopub.status.idle": "2025-10-12T11:00:05.882758Z",
     "shell.execute_reply": "2025-10-12T11:00:05.881721Z",
     "shell.execute_reply.started": "2025-10-12T10:54:08.021876Z"
    },
    "id": "AVmJ4NQ7wo6W",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Processing catalog content and extracting text features...\n",
      "Loading SentenceTransformer model: all-MiniLM-L6-v2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "Fitting CatalogDataTransformer on training data...\n",
      "Learned median 'Value' for imputation: 16.0\n",
      "Transforming catalog data... (DataFrame shape: (150000, 4))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/input/helpers/cat_transform.py:56: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  transformed_df['Value'].fillna(self.median_value, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation complete.\n",
      "Extracting text features...\n",
      "Generating text embeddings... (This may take a moment)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731dee5298a64ef083a89cab37ea2ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text embeddings generated.\n",
      "Feature extraction complete. Final DataFrame shape: (150000, 398)\n"
     ]
    }
   ],
   "source": [
    "# -- 3. Extract Catalog & Text Features --\n",
    "print(\"\\nStep 3: Processing catalog content and extracting text features...\")\n",
    "# Instantiate transformers\n",
    "catalog_transformer = CatalogDataTransformer()\n",
    "text_feature_extractor = CatalogFeatureExtractor()\n",
    "\n",
    "# Fit the catalog transformer ONLY on the training data to prevent data leakage\n",
    "catalog_transformer.fit(train_df)\n",
    "\n",
    "# Transform the ENTIRE combined dataset\n",
    "processed_all_df = catalog_transformer.transform(all_df)\n",
    "\n",
    "# Extract text features from the transformed combined dataset\n",
    "catalog_features_df = text_feature_extractor.extract_features(processed_all_df)\n",
    "# Drop the raw text column as it's no longer needed\n",
    "catalog_features_df = catalog_features_df.drop(columns=['all_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T11:00:50.164621Z",
     "iopub.status.busy": "2025-10-12T11:00:50.163843Z",
     "iopub.status.idle": "2025-10-12T11:26:44.021309Z",
     "shell.execute_reply": "2025-10-12T11:26:44.020472Z",
     "shell.execute_reply.started": "2025-10-12T11:00:50.164595Z"
    },
    "id": "lxUPj-NPwtgl",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Extracting image features using CLIP...\n",
      "Loading CLIP model: clip-ViT-B-32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP model loaded successfully.\n",
      "Processing 150000 images in 6 chunks of size 25000...\n",
      "--- Processing chunk 1/6 (rows 0 to 24999) ---\n",
      "Preparing images for feature extraction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 25000/25000 [01:54<00:00, 218.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding images to feature vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d5ec5abb9140e5ac56f75c6e5337fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image feature extraction complete. Shape: (25000, 513)\n",
      "--- Processing chunk 2/6 (rows 25000 to 49999) ---\n",
      "Preparing images for feature extraction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 25000/25000 [01:50<00:00, 226.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding images to feature vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa5d724b0f0457f922b26877abb015e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image feature extraction complete. Shape: (25000, 513)\n",
      "--- Processing chunk 3/6 (rows 50000 to 74999) ---\n",
      "Preparing images for feature extraction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 25000/25000 [01:50<00:00, 227.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding images to feature vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4ae905c6594f828f849e8586056449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image feature extraction complete. Shape: (25000, 513)\n",
      "--- Processing chunk 4/6 (rows 75000 to 99999) ---\n",
      "Preparing images for feature extraction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 25000/25000 [01:51<00:00, 224.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding images to feature vectors...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd329abc30849ceac105a2ff50f6c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image feature extraction complete. Shape: (25000, 513)\n",
      "--- Processing chunk 5/6 (rows 100000 to 124999) ---\n",
      "Preparing images for feature extraction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 25000/25000 [01:51<00:00, 224.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding images to feature vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7341450b4304e2d875535d5a3540915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image feature extraction complete. Shape: (25000, 513)\n",
      "--- Processing chunk 6/6 (rows 125000 to 149999) ---\n",
      "Preparing images for feature extraction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 100%|██████████| 25000/25000 [01:52<00:00, 221.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding images to feature vectors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fabe4b4e1904230a83a4ead3c64ff7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image feature extraction complete. Shape: (25000, 513)\n",
      "\n",
      "Combining features from all chunks...\n",
      "✅ Image feature extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# -- 4. Extract Image Features (Memory-Efficient Version) --\n",
    "print(\"\\nStep 4: Extracting image features using CLIP...\")\n",
    "clip_extractor = CLIPImageFeatureExtractor()\n",
    "\n",
    "# Define a chunk size\n",
    "CHUNK_SIZE = 25000\n",
    "num_chunks = int(np.ceil(len(all_df) / CHUNK_SIZE))\n",
    "all_image_features = [] # List to store feature DataFrames from each chunk\n",
    "\n",
    "print(f\"Processing {len(all_df)} images in {num_chunks} chunks of size {CHUNK_SIZE}...\")\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    start_idx = i * CHUNK_SIZE\n",
    "    end_idx = min((i + 1) * CHUNK_SIZE, len(all_df))\n",
    "    \n",
    "    print(f\"--- Processing chunk {i+1}/{num_chunks} (rows {start_idx} to {end_idx-1}) ---\")\n",
    "    \n",
    "    # Get the current chunk of the dataframe\n",
    "    df_chunk = all_df.iloc[start_idx:end_idx]\n",
    "    \n",
    "    # Extract features for this chunk\n",
    "    chunk_features_df = clip_extractor.extract_features(df_chunk, image_path_col='image_path')\n",
    "    \n",
    "    # Append the result to our list\n",
    "    all_image_features.append(chunk_features_df)\n",
    "    \n",
    "    # Optional: clean up memory\n",
    "    import gc\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\nCombining features from all chunks...\")\n",
    "# Concatenate all the feature dataframes into one\n",
    "image_features_df = pd.concat(all_image_features, ignore_index=True)\n",
    "\n",
    "# Keep only sample_id and image features for merging\n",
    "image_feature_cols = ['sample_id'] + [col for col in image_features_df.columns if 'img_feat' in col]\n",
    "image_features_df = image_features_df[image_feature_cols]\n",
    "\n",
    "print(\"✅ Image feature extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T11:27:34.579738Z",
     "iopub.status.busy": "2025-10-12T11:27:34.579003Z",
     "iopub.status.idle": "2025-10-12T11:27:36.603605Z",
     "shell.execute_reply": "2025-10-12T11:27:36.603008Z",
     "shell.execute_reply.started": "2025-10-12T11:27:34.579708Z"
    },
    "id": "vb0cyb03wvVP",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5: Merging all features into a final matrix...\n"
     ]
    }
   ],
   "source": [
    "# -- 5. Merge, Scale, and Finalize Features --\n",
    "print(\"\\nStep 5: Merging all features into a final matrix...\")\n",
    "# Merge catalog and image features\n",
    "final_features_df = pd.merge(catalog_features_df, image_features_df, on='sample_id', how='left')\n",
    "\n",
    "# Fill any NaNs in image features (from failed merges) with 0\n",
    "img_cols = [col for col in final_features_df.columns if 'img_feat' in col]\n",
    "final_features_df[img_cols] = final_features_df[img_cols].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T11:27:41.887131Z",
     "iopub.status.busy": "2025-10-12T11:27:41.886450Z",
     "iopub.status.idle": "2025-10-12T11:27:42.948927Z",
     "shell.execute_reply": "2025-10-12T11:27:42.948051Z",
     "shell.execute_reply.started": "2025-10-12T11:27:41.887103Z"
    },
    "id": "gSNYYHu4wxmh",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 6: Splitting combined data back into Train and Test sets...\n"
     ]
    }
   ],
   "source": [
    "# -- 6. Split back into Train and Test sets --\n",
    "print(\"\\nStep 6: Splitting combined data back into Train and Test sets...\")\n",
    "# Use the stored sample_ids to perform a clean split\n",
    "train_mask = final_features_df['sample_id'].isin(train_ids)\n",
    "X = final_features_df.drop(columns=['sample_id'])\n",
    "\n",
    "X_train = X[train_mask].reset_index(drop=True)\n",
    "X_test = X[~train_mask].reset_index(drop=True)\n",
    "y_train = np.log1p(y_train_raw) # Apply log transform to the target\n",
    "\n",
    "# Store test_ids for final submission (from the original test_df)\n",
    "test_ids_final = test_df['sample_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T11:27:47.864248Z",
     "iopub.status.busy": "2025-10-12T11:27:47.863609Z",
     "iopub.status.idle": "2025-10-12T11:27:48.135987Z",
     "shell.execute_reply": "2025-10-12T11:27:48.135116Z",
     "shell.execute_reply.started": "2025-10-12T11:27:47.864221Z"
    },
    "id": "ibXAS5Xkw2XT",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 7: Applying StandardScaler...\n",
      "\n",
      "--- Feature Extraction Complete ---\n",
      "Shape of X_train: (75000, 908)\n",
      "Shape of y_train: (75000,)\n",
      "Shape of X_test: (75000, 908)\n",
      "NaN values in X_train: 0\n",
      "NaN values in X_test: 0\n",
      "\n",
      "✅ Success! X_train and X_test have the same feature dimensions.\n"
     ]
    }
   ],
   "source": [
    "# -- 7. Scale Numerical Features --\n",
    "print(\"\\nStep 7: Applying StandardScaler...\")\n",
    "scaler = StandardScaler()\n",
    "columns_to_scale = ['Value', 'IPQ']\n",
    "\n",
    "# Fit scaler ONLY on training data\n",
    "X_train[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
    "\n",
    "# Transform test data using the scaler fitted on training data\n",
    "X_test[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n",
    "\n",
    "\n",
    "# -- Final Verification --\n",
    "print(\"\\n--- Feature Extraction Complete ---\")\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "\n",
    "# Check for any NaN values\n",
    "print(f\"NaN values in X_train: {X_train.isna().sum().sum()}\")\n",
    "print(f\"NaN values in X_test: {X_test.isna().sum().sum()}\")\n",
    "\n",
    "assert X_train.shape[1] == X_test.shape[1], f\"CRITICAL ERROR: Train ({X_train.shape[1]}) and test ({X_test.shape[1]}) sets have different feature dimensions!\"\n",
    "print(\"\\n✅ Success! X_train and X_test have the same feature dimensions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T11:27:57.465942Z",
     "iopub.status.busy": "2025-10-12T11:27:57.465132Z",
     "iopub.status.idle": "2025-10-12T11:28:07.431153Z",
     "shell.execute_reply": "2025-10-12T11:28:07.430196Z",
     "shell.execute_reply.started": "2025-10-12T11:27:57.465885Z"
    },
    "id": "5BfX6z5Dxn0C",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'transformed_data' created or already exists.\n",
      "Saving X_train to 'transformed_data/X_train.parquet'...\n",
      "Saving y_train to 'transformed_data/y_train.parquet'...\n",
      "Saving X_test to 'transformed_data/X_test.parquet'...\n",
      "\n",
      "✅ All processed data has been successfully saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory to save the processed data\n",
    "SAVE_DIR = 'transformed_data'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "print(f\"Directory '{SAVE_DIR}' created or already exists.\")\n",
    "\n",
    "# Define file paths\n",
    "x_train_path = os.path.join(SAVE_DIR, 'X_train.parquet')\n",
    "y_train_path = os.path.join(SAVE_DIR, 'y_train.parquet')\n",
    "x_test_path = os.path.join(SAVE_DIR, 'X_test.parquet')\n",
    "\n",
    "# --- Save the DataFrames to Parquet files ---\n",
    "\n",
    "# Save X_train\n",
    "print(f\"Saving X_train to '{x_train_path}'...\")\n",
    "X_train.to_parquet(x_train_path)\n",
    "\n",
    "# Save y_train (converting Series to DataFrame for saving)\n",
    "print(f\"Saving y_train to '{y_train_path}'...\")\n",
    "y_train.to_frame(name='price_log1p').to_parquet(y_train_path)\n",
    "\n",
    "# Save X_test\n",
    "print(f\"Saving X_test to '{x_test_path}'...\")\n",
    "X_test.to_parquet(x_test_path)\n",
    "\n",
    "print(\"\\n✅ All processed data has been successfully saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T11:28:12.817872Z",
     "iopub.status.busy": "2025-10-12T11:28:12.817236Z",
     "iopub.status.idle": "2025-10-12T11:28:12.821926Z",
     "shell.execute_reply": "2025-10-12T11:28:12.820966Z",
     "shell.execute_reply.started": "2025-10-12T11:28:12.817837Z"
    },
    "id": "YQ2u1SIAyYYR",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-10-12T10:43:20.528Z"
    },
    "id": "OdQXcWn-yag4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # -- 1. Load the Processed Data --\n",
    "# print(\"Loading pre-processed data...\")\n",
    "# DATA_DIR = 'transformed_data'\n",
    "# X_train = pd.read_parquet(os.path.join(DATA_DIR, 'X_train.parquet'))\n",
    "# y_train = pd.read_parquet(os.path.join(DATA_DIR, 'y_train.parquet')).squeeze()\n",
    "# X_test = pd.read_parquet(os.path.join(DATA_DIR, 'X_test.parquet'))\n",
    "# test_ids = pd.read_csv(\"/content/student_resource/dataset/test.csv\")['sample_id']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T11:51:02.010030Z",
     "iopub.status.busy": "2025-10-12T11:51:02.009121Z",
     "iopub.status.idle": "2025-10-12T11:51:02.017683Z",
     "shell.execute_reply": "2025-10-12T11:51:02.016740Z",
     "shell.execute_reply.started": "2025-10-12T11:51:02.009997Z"
    },
    "id": "vpH91F4qydtA",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting up LightGBM model and 5-Fold Cross-Validation...\n"
     ]
    }
   ],
   "source": [
    "# -- 2. Set up the Model and Cross-Validation --\n",
    "print(\"\\nSetting up LightGBM model and 5-Fold Cross-Validation...\")\n",
    "\n",
    "# LightGBM model parameters (these can be tuned for better performance)\n",
    "params = {\n",
    "    'objective': 'regression_l1', # MAE is often more robust to outliers\n",
    "    'metric': 'rmse',\n",
    "    'device': 'gpu',\n",
    "    'n_estimators': 20000,        # High number, will be stopped by early stopping\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'lambda_l1': 0.1,\n",
    "    'lambda_l2': 0.1,\n",
    "    'num_leaves': 31,\n",
    "    'verbose': -1,\n",
    "    'n_jobs': -1,                 # Use all available cores\n",
    "    'seed': 42,\n",
    "    'boosting_type': 'gbdt',\n",
    "}\n",
    "\n",
    "# K-Fold setup\n",
    "N_SPLITS = 5\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "# Arrays to store predictions\n",
    "oof_predictions = np.zeros(X_train.shape[0])\n",
    "test_predictions = np.zeros(X_test.shape[0])\n",
    "fold_scores = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T11:54:37.843567Z",
     "iopub.status.busy": "2025-10-12T11:54:37.843252Z",
     "iopub.status.idle": "2025-10-12T11:54:37.963176Z",
     "shell.execute_reply": "2025-10-12T11:54:37.962334Z",
     "shell.execute_reply.started": "2025-10-12T11:54:37.843545Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting data to float32 for GPU efficiency...\n",
      "✅ Data conversion complete.\n",
      "Starting training with 5-fold CV...\n"
     ]
    }
   ],
   "source": [
    "# --- Convert data for optimal GPU performance ---\n",
    "print(\"Converting data to float32 for GPU efficiency...\")\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "# Ensure the target variable is also in a compatible format\n",
    "# y_train is likely a pandas Series, converting its values is good practice\n",
    "y_train = y_train.astype(np.float32)\n",
    "\n",
    "print(\"✅ Data conversion complete.\")\n",
    "\n",
    "\n",
    "# -- 3. Run the Cross-Validation Loop --\n",
    "print(f\"Starting training with {N_SPLITS}-fold CV...\")\n",
    "# (Your existing training loop code follows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T11:54:46.131766Z",
     "iopub.status.busy": "2025-10-12T11:54:46.131002Z",
     "iopub.status.idle": "2025-10-12T13:49:11.600805Z",
     "shell.execute_reply": "2025-10-12T13:49:11.598444Z",
     "shell.execute_reply.started": "2025-10-12T11:54:46.131738Z"
    },
    "id": "CzGgUYU2yhH9",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with 5-fold CV...\n",
      "--- Fold 1/5 ---\n",
      "Fold 1 RMSE: 0.71257\n",
      "--- Fold 2/5 ---\n",
      "Fold 2 RMSE: 0.69339\n",
      "--- Fold 3/5 ---\n",
      "Fold 3 RMSE: 0.69236\n",
      "--- Fold 4/5 ---\n",
      "Fold 4 RMSE: 0.67930\n",
      "--- Fold 5/5 ---\n",
      "Fold 5 RMSE: 0.69258\n"
     ]
    }
   ],
   "source": [
    "# -- 3. Run the Cross-Validation Loop --\n",
    "print(f\"Starting training with {N_SPLITS}-fold CV...\")\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X_train, y_train)):\n",
    "    print(f\"--- Fold {fold+1}/{N_SPLITS} ---\")\n",
    "\n",
    "    # Split the data for this fold\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(X_train_fold, y_train_fold,\n",
    "              eval_set=[(X_val_fold, y_val_fold)],\n",
    "              eval_metric='rmse',\n",
    "              callbacks=[lgb.early_stopping(100, verbose=False)])\n",
    "\n",
    "    # Make predictions\n",
    "    val_preds = model.predict(X_val_fold)\n",
    "    oof_predictions[val_index] = val_preds\n",
    "    test_predictions += model.predict(X_test) / N_SPLITS # Average predictions over folds\n",
    "\n",
    "    # Evaluate fold performance\n",
    "    fold_rmse = np.sqrt(mean_squared_error(y_val_fold, val_preds))\n",
    "    fold_scores.append(fold_rmse)\n",
    "    print(f\"Fold {fold+1} RMSE: {fold_rmse:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T13:49:18.022833Z",
     "iopub.status.busy": "2025-10-12T13:49:18.022550Z",
     "iopub.status.idle": "2025-10-12T13:49:18.184269Z",
     "shell.execute_reply": "2025-10-12T13:49:18.183313Z",
     "shell.execute_reply.started": "2025-10-12T13:49:18.022810Z"
    },
    "id": "jcTvS5ooyi9x",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Complete ---\n",
      "Average CV RMSE across all folds: 0.69404\n",
      "\n",
      "✅ Submission file 'submission.csv' has been created successfully!\n",
      "Submission shape: (75000, 2)\n",
      "Submission file head:\n",
      "   sample_id      price\n",
      "0     100179  15.564337\n",
      "1     245611  18.533813\n",
      "2     146263  18.395008\n",
      "3      95658   8.395778\n",
      "4      36806  24.383568\n"
     ]
    }
   ],
   "source": [
    "# -- 4. Evaluate Overall Performance and Create Submission --\n",
    "print(\"\\n--- Training Complete ---\")\n",
    "mean_cv_score = np.mean(fold_scores)\n",
    "print(f\"Average CV RMSE across all folds: {mean_cv_score:.5f}\")\n",
    "\n",
    "# Inverse transform the predictions from log scale back to price scale\n",
    "final_predictions = np.expm1(test_predictions)\n",
    "\n",
    "# Create submission file\n",
    "submission_df = pd.DataFrame({'sample_id': test_ids, 'price': final_predictions})\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\n✅ Submission file 'submission.csv' has been created successfully!\")\n",
    "print(f\"Submission shape: {submission_df.shape}\")\n",
    "print(\"Submission file head:\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T13:49:32.076059Z",
     "iopub.status.busy": "2025-10-12T13:49:32.075705Z",
     "iopub.status.idle": "2025-10-12T13:49:32.219349Z",
     "shell.execute_reply": "2025-10-12T13:49:32.218409Z",
     "shell.execute_reply.started": "2025-10-12T13:49:32.076021Z"
    },
    "id": "ESg7CaAjzP1J",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Submission file saved successfully as 'submission.csv'!\n"
     ]
    }
   ],
   "source": [
    "# The submission_df should already be created from the previous step.\n",
    "# If not, ensure the model has been trained and predictions have been made.\n",
    "\n",
    "# Define the filename for the submission\n",
    "submission_filename = 'submission.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# The index=False argument is crucial to prevent pandas from writing the\n",
    "# DataFrame's index as an extra column in the file.\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"✅ Submission file saved successfully as '{submission_filename}'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T13:50:40.038392Z",
     "iopub.status.busy": "2025-10-12T13:50:40.038034Z",
     "iopub.status.idle": "2025-10-12T13:50:40.055759Z",
     "shell.execute_reply": "2025-10-12T13:50:40.055008Z",
     "shell.execute_reply.started": "2025-10-12T13:50:40.038366Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75000 entries, 0 to 74999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   sample_id  75000 non-null  int64  \n",
      " 1   price      75000 non-null  float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "submission_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8462196,
     "sourceId": 13344400,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8462273,
     "sourceId": 13344502,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8463830,
     "sourceId": 13346458,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
